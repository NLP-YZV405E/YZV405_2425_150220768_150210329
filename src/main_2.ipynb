{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa2537e954d48efbf8376bc150b0453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from dataset import IdiomDataset\n",
    "from transformers import BertConfig, BertTokenizer, BertModel\n",
    "from utils import *\n",
    "\n",
    "SEED = 2\n",
    "# set seeds to get reproducible results\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "# gpuda bazen randomluk olabiliyormuş onu kaldırmak için\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# create bert\n",
    "model_name = 'bert-base-multilingual-cased'\n",
    "# output hidden states -> it helps to get hidden states from bert\n",
    "bert_config = BertConfig.from_pretrained(model_name, output_hidden_states=True)\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "# get bert weights\n",
    "bert_model = BertModel.from_pretrained(model_name, config=bert_config)\n",
    "\n",
    "# train, update or test mode selection\n",
    "mode = input(\"Do you want to train or test the model? (train, update, test): \").strip().lower()\n",
    "assert mode in ['train', 'update', 'test'], \"Mode must be one of train, update, test\"\n",
    "# select the dataset\n",
    "dataset_selection = input(\"Select the dataset (ID10M, ITU, PARSEME): \").strip().upper()\n",
    "assert dataset_selection in ['ID10M', 'ITU', 'PARSEME'], \"Dataset must be one of ID10M, ITU, PARSEME\"\n",
    "\n",
    "# we dont have test set for ITU dataset\n",
    "if mode == \"test\" and dataset_selection == \"ITU\":\n",
    "    assert False, \"Test mode is not available for ITU dataset. Please use update mode instead.\"\n",
    "\n",
    "# test ve update için parametrelerin pathini alıcaz,\n",
    "# update -> mesela ID10M'de train ettik,  ITU ile parametreleri finetune etcez\n",
    "# test -> parametleri freezeleyip test edicez\n",
    "# farklı checkpointler yaparız, mesela after ID10M, after ID10M + ITU etc\n",
    "\n",
    "if mode in [\"test\",\"update\"]:\n",
    "    # load the model\n",
    "    checkpoint = input(\"Enter the path of the model: \").strip()\n",
    "    assert os.path.exists(checkpoint), \"Model path does not exist\"\n",
    "\n",
    "# get stanza tagger for both languages\n",
    "tagger_dict = initialize(use_gpu=True)\n",
    "\n",
    "# get the path for the dataset\n",
    "main_path = r\"./resources/\"+dataset_selection+\"/\"\n",
    "train_file = main_path + \"train.tsv\"\n",
    "dev_file = main_path + \"dev.tsv\"\n",
    "test_file = main_path + \"test.tsv\"\n",
    "\n",
    "labels_vocab = {\"<pad>\":0, \"B-IDIOM\":1, \"I-IDIOM\":2, \"O\":3}\n",
    "\n",
    "# initialize the dataset\n",
    "train_dataset, dev_dataset, test_dataset = None, None, None\n",
    "if mode in [\"train\", \"update\"]:\n",
    "    train_dataset = IdiomDataset(train_file, bert_tokenizer, labels_vocab, tagger_dict)\n",
    "    dev_dataset = IdiomDataset(dev_file, bert_tokenizer, labels_vocab, tagger_dict)\n",
    "    print(f\"train sentences: {len(train_dataset)}\")\n",
    "    print(f\"dev sentences: {len(dev_dataset)}\")\n",
    "    print(\"-\" * 50 + \"\\n\")\n",
    "else:\n",
    "    train_dataset = IdiomDataset(train_file, bert_tokenizer, labels_vocab, tagger_dict)\n",
    "    test_dataset = IdiomDataset(test_file, bert_tokenizer, labels_vocab, tagger_dict) \n",
    "    print(f\"test sentences: {len(test_dataset)}\")\n",
    "    print(\"-\" * 50 + \"\\n\")\n",
    "\n",
    "\n",
    "idioms_train, idioms_dev, idioms_test = None, None, None\n",
    "\n",
    "if mode in [\"train\", \"update\"]:\n",
    "    idioms_train = get_idioms(train_dataset, tagger_dict)\n",
    "    idioms_dev = get_idioms(dev_dataset, tagger_dict)\n",
    "    print(f\"Idioms in train: {len(idioms_train)}\")\n",
    "    print(f\"Idioms in dev: {len(idioms_dev)}\")\n",
    "    percentage_elements_in_train_also_in_dev = overlap_percentage_l1_in_l2(idioms_dev, idioms_train)\n",
    "    print(f\"Percentage of idioms in train also in dev: {percentage_elements_in_train_also_in_dev}\")\n",
    "    print(\"-\" * 50 + \"\\n\")\n",
    "else:\n",
    "    idioms_train = get_idioms(train_dataset, tagger_dict)\n",
    "    idioms_test = get_idioms(test_dataset, tagger_dict)\n",
    "    print(f\"Idioms in test: {len(idioms_test)}\")\n",
    "    percentage_elements_in_train_also_in_test = overlap_percentage_l1_in_l2(idioms_test, idioms_train)\n",
    "    print(f\"Percentage of idioms in train also in test: {percentage_elements_in_train_also_in_test}\")\n",
    "    print(\"-\" * 50 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
