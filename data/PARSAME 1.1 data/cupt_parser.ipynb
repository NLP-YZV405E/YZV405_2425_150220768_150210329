{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_width = 20\n",
    "tag_width = 10\n",
    "lang_width = 10\n",
    "\n",
    "def parse_cupt(file_path):\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    \n",
    "    with open(file_path, encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"#\") or line == \"\":\n",
    "                if line == \"\" and sentence:\n",
    "                    sentences.append(sentence)\n",
    "                    sentence = []\n",
    "                continue\n",
    "            columns = line.split('\\t')\n",
    "            sentence.append(columns)\n",
    "    \n",
    "    if sentence:\n",
    "        sentences.append(sentence)\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "def tranform_cupt_to_tsv(input_path, output_path, lang):\n",
    "    \n",
    "    cupt_data = parse_cupt(input_path)\n",
    "\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        for sentence in cupt_data:\n",
    "            switch = False\n",
    "            for token in sentence:\n",
    "                if token[1] == \"_\":\n",
    "                    continue\n",
    "                file.write(token[1] + \"\\t\")\n",
    "                if token[-1] ==\"*\":\n",
    "                    file.write(\"O\\t\")\n",
    "                elif token[-1] != \"O\" and switch == False:\n",
    "                    file.write(\"B-IDIOM\\t\")\n",
    "                    switch = True\n",
    "                else:\n",
    "                    file.write(\"I-IDIOM\\t\")\n",
    "                file.write(lang + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', 'Şu', 'şu', 'Det', '_', '_', '2', 'DETERMINER', '_', '_', '*']\n",
      "['2', 'anda', 'an', 'Noun', '_', 'A3sg|Loc|Pnon', '12', 'MODIFIER', '_', '_', '*']\n",
      "['3', 'bir', 'bir', 'Adj', 'Num', '_', '5', 'DETERMINER', '_', '_', '*']\n",
      "['4', 'tek', 'tek', 'Adj', '_', '_', '5', 'MODIFIER', '_', '_', '*']\n",
      "['5', 'grup', 'grup', 'Noun', '_', 'A3sg|Nom|Pnon', '12', 'MODIFIER', '_', '_', '*']\n",
      "['6', 'KOBİ', 'Kobi', 'Noun', 'Prop', 'A3sg|Nom|Pnon', '9', 'POSSESSOR', '_', '_', '*']\n",
      "['7', \"'lere\", \"'lere\", '?', '_', '_', '8', 'ARGUMENT', '_', '_', '*']\n",
      "['8', 'yönelik', 'yönelik', 'Postp', 'PCDat', '_', '9', 'MODIFIER', '_', '_', '*']\n",
      "['9', 'faaliyetlerini', 'faaliyet', 'Noun', '_', 'A3pl|Acc|P3pl', '10', 'OBJECT', '_', '_', '*']\n",
      "['10', '_', 'artır', 'Verb', '_', 'Pos', '11', 'DERIV', '_', '_', '*']\n",
      "['11', 'artırmaya', '_', 'Noun', 'Inf2', 'A3sg|Dat|Pnon', '12', 'MODIFIER', '_', '_', '*']\n",
      "['12', 'çalışıyor', 'çalış', 'Verb', '_', 'A3sg|Pos|Prog1', '0', 'PREDICATE', '_', '_', '*']\n",
      "['13', ':', ':', 'Punc', '_', '_', '12', 'PUNCTUATION', '_', '_', '*']\n",
      "['14', 'Bankalar', 'banka', 'Noun', '_', 'A3pl|Nom|Pnon', '12', 'SUBJECT', '_', '_', '*']\n",
      "['15', '.', '.', 'Punc', '_', '_', '14', 'PUNCTUATION', '_', '_', '*']\n"
     ]
    }
   ],
   "source": [
    "cupt_data = parse_cupt(r\"./sharedtask-1.1-TR/train.cupt\")\n",
    "for token in cupt_data[0]:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', 'Türkiye', 'Türkiye', 'Noun', 'Prop', 'A3sg|Nom|Pnon', '17', 'SUBJECT', '_', '_', '*']\n",
      "['2', \"'de\", \"'de\", '?', '_', '_', '3', 'MODIFIER', '_', '_', '*']\n",
      "['3', 'bankaların', 'banka', 'Noun', '_', 'A3pl|Gen|Pnon', '6', 'POSSESSOR', '_', '_', '*']\n",
      "['4', 'bir', 'bir', 'Adj', 'Num', '_', '6', 'DETERMINER', '_', '_', '*']\n",
      "['5', 'siyasi', 'siyasi', 'Adj', '_', '_', '6', 'MODIFIER', '_', '_', '*']\n",
      "['6', 'gücü', 'güç', 'Noun', 'NAdj', 'A3sg|Nom|P3sg', '8', 'SUBJECT', '_', '_', '*']\n",
      "['7', 'de', 'de', 'Conj', '_', '_', '6', 'INTENSIFIER', '_', '_', '*']\n",
      "['8', 'var', 'var', 'Adj', '_', '_', '17', 'COORDINATION', '_', '_', '*']\n",
      "['9', ',', ',', 'Punc', '_', '_', '8', 'PUNCTUATION', '_', '_', '*']\n",
      "['10', 'bu', 'bu', 'Det', '_', '_', '11', 'DETERMINER', '_', '_', '*']\n",
      "['11', 'nedenle', 'neden', 'Noun', '_', 'A3sg|Ins|Pnon', '13', 'MODIFIER', '_', '_', '*']\n",
      "['12', 'ilerde', 'ilerd', 'Noun', '_', 'A3sg|Dat|Pnon', '13', 'MODIFIER', '_', '_', '*']\n",
      "['13', '_', 'örgütle', 'Verb', '_', 'Pass|Pos', '14', 'DERIV', '_', '_', '*']\n",
      "['14', 'örgütlenmeye', '_', 'Noun', 'Inf2', 'A3sg|Dat|Pnon', '17', 'MODIFIER', '_', '_', '*']\n",
      "['15', 'de', 'de', 'Conj', '_', '_', '14', 'INTENSIFIER', '_', '_', '*']\n",
      "['16', 'yardımcı', 'yardımcı', 'Noun', '_', 'A3sg|Nom|Pnon', '17', 'MWE', '_', '_', '1:LVC.full']\n",
      "['17', 'olabilirler', 'ol', 'Verb', '_', 'A3pl|Able|Aor|Pos', '0', 'PREDICATE', '_', '_', '1']\n",
      "['18', '.', '.', 'Punc', '_', '_', '17', 'PUNCTUATION', '_', '_', '*']\n"
     ]
    }
   ],
   "source": [
    "for token in cupt_data[1]:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Ensure output folders exist\n",
    "os.makedirs(r\"./transformed-TR\", exist_ok=True)\n",
    "os.makedirs(r\"./transformed-IT\", exist_ok=True)\n",
    "\n",
    "# Transform Turkish\n",
    "tranform_cupt_to_tsv(r\"./sharedtask-1.1-TR/train.cupt\", r\"./transformed-TR/train.tsv\",\"tr\")\n",
    "tranform_cupt_to_tsv(r\"./sharedtask-1.1-TR/dev.cupt\", r\"./transformed-TR/dev.tsv\",\"tr\")\n",
    "tranform_cupt_to_tsv(r\"./sharedtask-1.1-TR/test.cupt\", r\"./transformed-TR/test.tsv\",\"tr\")\n",
    "\n",
    "# Transform Italian\n",
    "tranform_cupt_to_tsv(r\"./sharedtask-1.1-IT/train.cupt\", r\"./transformed-IT/train.tsv\",\"it\")\n",
    "tranform_cupt_to_tsv(r\"./sharedtask-1.1-IT/dev.cupt\", r\"./transformed-IT/dev.tsv\",\"it\")\n",
    "tranform_cupt_to_tsv(r\"./sharedtask-1.1-IT/test.cupt\", r\"./transformed-IT/test.tsv\",\"it\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_tsv_files(tr_path, it_path, output_path):\n",
    "    with open(tr_path, \"r\", encoding=\"utf-8\") as f_tr, \\\n",
    "         open(it_path, \"r\", encoding=\"utf-8\") as f_it, \\\n",
    "         open(output_path, \"w\", encoding=\"utf-8\") as f_out:\n",
    "\n",
    "        tr_lines = f_tr.readlines()\n",
    "        it_lines = f_it.readlines()\n",
    "        f_out.writelines(tr_lines + it_lines)\n",
    "\n",
    "# Create output folder\n",
    "os.makedirs(\"./combined-tsv\", exist_ok=True)\n",
    "\n",
    "# Combine train, dev, test TSVs\n",
    "combine_tsv_files(\"./transformed-TR/train.tsv\", \"./transformed-IT/train.tsv\", r\"../resources/PARSAME/train.tsv\")\n",
    "combine_tsv_files(\"./transformed-TR/dev.tsv\", \"./transformed-IT/dev.tsv\", r\"../resources/PARSAME/dev.tsv\")\n",
    "combine_tsv_files(\"./transformed-TR/test.tsv\", \"./transformed-IT/test.tsv\", r\"../resources/PARSAME/test.tsv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
